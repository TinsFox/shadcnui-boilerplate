import path from "node:path";

import fs from "node:fs/promises";
import chalk from "chalk";
import { glob } from "glob";
import type { Package } from "./scanner";
import { readJsonFile, writeJsonFile } from "./utils/file";
import { logger } from "./utils/logger";

interface RenameOptions {
	/** å½“å‰ç»„ç»‡å */
	oldOrg: string;
	/** æ–°ç»„ç»‡å */
	newOrg: string;
	/** éœ€è¦å¤„ç†çš„åŒ…åˆ—è¡¨ */
	packages: Package[];
	/** æ˜¯å¦ä»…é¢„è§ˆè€Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶ */
	dryRun: boolean;
	/** è¦åŒ…å«çš„æ–‡ä»¶æ¨¡å¼ (glob patterns) */
	include?: string[];
	/** è¦æ’é™¤çš„æ–‡ä»¶æ¨¡å¼ (glob patterns) */
	exclude?: string[];
	/** æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†æ—¥å¿— */
	verbose?: boolean;
}

interface RenameResult {
	/** ä¿®æ”¹çš„æ–‡ä»¶æ•°é‡ */
	modifiedFiles: number;
	/** ä¿®æ”¹çš„åŒ…æ•°é‡ */
	modifiedPackages: number;
	/** ä¿®æ”¹çš„æ–‡ä»¶åˆ—è¡¨ */
	files: string[];
}

/**
 * é‡å‘½åç»„ç»‡å
 * @param options é‡å‘½åé€‰é¡¹
 * @returns é‡å‘½åç»“æœ
 */
export async function renameOrganization(
	options: RenameOptions,
): Promise<RenameResult> {
	const { oldOrg, newOrg, packages, dryRun } = options;
	const result: RenameResult = {
		modifiedFiles: 0,
		modifiedPackages: 0,
		files: [],
	};

	// ç¡®ä¿ç»„ç»‡åæ ¼å¼æ­£ç¡®
	const oldOrgNormalized = oldOrg.startsWith("@") ? oldOrg : `@${oldOrg}`;
	const newOrgNormalized = newOrg.startsWith("@") ? newOrg : `@${newOrg}`;

	logger.info(
		`ğŸ”„ Renaming from ${chalk.cyan(oldOrgNormalized)} to ${chalk.green(newOrgNormalized)}...`,
	);

	// å¤„ç†æ¯ä¸ªåŒ…
	for (const pkg of packages) {
		let packageModified = false;
		logger.info(`ğŸ“‚ Processing package: ${chalk.yellow(pkg.name)}`);

		// 1. æ›´æ–° package.json
		const packageJsonPath = path.join(pkg.location, "package.json");
		try {
			const packageJson = await readJsonFile(packageJsonPath);

			// æ›´æ–°åŒ…å
			if (packageJson.name.startsWith(oldOrgNormalized)) {
				const newName = packageJson.name.replace(
					oldOrgNormalized,
					newOrgNormalized,
				);
				logger.info(
					`  ${chalk.cyan(packageJson.name)} â†’ ${chalk.green(newName)}`,
				);

				if (!dryRun) {
					packageJson.name = newName;
					packageModified = true;
				}
			}

			// æ›´æ–°ä¾èµ–å…³ç³»
			const dependencyTypes = [
				"dependencies",
				"devDependencies",
				"peerDependencies",
				"optionalDependencies",
			];

			for (const depType of dependencyTypes) {
				if (packageJson[depType]) {
					const updatedDeps: Record<string, string> = {};
					let depsModified = false;

					for (const [dep, version] of Object.entries(packageJson[depType])) {
						if (dep.startsWith(oldOrgNormalized)) {
							const newDep = dep.replace(oldOrgNormalized, newOrgNormalized);
							logger.info(`  ${chalk.cyan(dep)} â†’ ${chalk.green(newDep)}`);
							updatedDeps[newDep] = version as string;
							depsModified = true;
							packageModified = true;
						} else {
							updatedDeps[dep] = version as string;
						}
					}

					if (depsModified && !dryRun) {
						packageJson[depType] = updatedDeps;
					}
				}
			}

			// ä¿å­˜ package.json
			if (packageModified && !dryRun) {
				await writeJsonFile(packageJsonPath, packageJson);
				result.files.push(packageJsonPath);
				result.modifiedFiles++;
			}
		} catch (error) {
			const err = error instanceof Error ? error : new Error(String(error));
			logger.error(`Error processing ${packageJsonPath}: ${err.message}`);
		}

		// 2. åœ¨æºæ–‡ä»¶ä¸­æ›¿æ¢å¯¼å…¥è¯­å¥å’Œå…¶ä»–å¼•ç”¨
		try {
			const sourceFiles = await getSourceFiles(
				pkg.location,
				options.include,
				options.exclude,
			);

			for (const file of sourceFiles) {
				try {
					let content = await fs.readFile(file, "utf-8");
					const originalContent = content;

					// ä½¿ç”¨æ›´å…¨é¢çš„æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å„ç§å¯¼å…¥/å¼•ç”¨æ¨¡å¼
					const patterns = [
						// åŸºæœ¬å­—ç¬¦ä¸²åŒ¹é… - åŒ¹é…æ‰€æœ‰å¼•å·å†…åŒ…å«ç»„ç»‡åçš„å­—ç¬¦ä¸²
						new RegExp(
							`(['"\`])${escapeRegExp(oldOrgNormalized)}/([^'"\`]+)(['"\`])`,
							"g",
						),

						// import è¯­å¥ï¼šimport { x } from '@old-org/package'
						// import x from '@old-org/package'
						// import * as x from '@old-org/package'
						new RegExp(
							`(import\\s+(?:\\{[^}]*\\}|\\*\\s+as\\s+[\\w$]+|[\\w$]+)\\s+from\\s+)(['"\`])${escapeRegExp(oldOrgNormalized)}/([^'"\`]+)(['"\`])`,
							"g",
						),

						// export è¯­å¥ï¼šexport { x } from '@old-org/package'
						// export * from '@old-org/package'
						// export { default } from '@old-org/package'
						new RegExp(
							`(export\\s+(?:\\{[^}]*\\}|\\*|\\{\\s*default\\s*(?:\\s*as\\s*[\\w$]+)?\\s*\\})\\s+from\\s+)(['"\`])${escapeRegExp(oldOrgNormalized)}/([^'"\`]+)(['"\`])`,
							"g",
						),

						// require è°ƒç”¨ï¼šrequire('@old-org/package')
						new RegExp(
							`(require\\s*\\()(['"\`])${escapeRegExp(oldOrgNormalized)}/([^'"\`]+)(['"\`])\\)`,
							"g",
						),

						// åŠ¨æ€å¯¼å…¥ï¼šimport('@old-org/package')
						new RegExp(
							`(import\\s*\\()(['"\`])${escapeRegExp(oldOrgNormalized)}/([^'"\`]+)(['"\`])\\)`,
							"g",
						),

						// JSX/TSX å±æ€§ä¸­çš„å¼•ç”¨ï¼špackageName="@old-org/package"
						new RegExp(
							`(\\w+\\s*=\\s*)(['"\`])${escapeRegExp(oldOrgNormalized)}/([^'"\`]+)(['"\`])`,
							"g",
						),

						// å¯¹è±¡å±æ€§ï¼š{ name: '@old-org/package' }
						new RegExp(
							`(:\\s*)(['"\`])${escapeRegExp(oldOrgNormalized)}/([^'"\`]+)(['"\`])`,
							"g",
						),
					];

					// åº”ç”¨æ¯ä¸ªæ¨¡å¼
					for (const pattern of patterns) {
						content = content.replace(
							pattern,
							(match, prefix, quote1, pkgPath, quote2) => {
								// å¯¹äºè¾ƒå¤æ‚çš„æ¨¡å¼ï¼Œä¿ç•™å‰ç¼€éƒ¨åˆ†
								if (prefix && quote1 && pkgPath && quote2) {
									return `${prefix}${quote1}${newOrgNormalized}/${pkgPath}${quote2}`;
								}
								// å¤„ç†åŸºæœ¬çš„å­—ç¬¦ä¸²æ›¿æ¢
								return match.replace(oldOrgNormalized, newOrgNormalized);
							},
						);
					}

					if (content !== originalContent) {
						logger.info(
							`  Modified: ${chalk.cyan(path.relative(process.cwd(), file))}`,
						);
						// æ·»åŠ ï¼šæ˜¾ç¤ºç®€å•çš„å·®å¼‚ä¿¡æ¯
						if (options.verbose) {
							// æ‰¾å‡ºå¹¶æ˜¾ç¤ºä¿®æ”¹çš„è¡Œ
							const originalLines = originalContent.split("\n");
							const newLines = content.split("\n");

							for (let i = 0; i < originalLines.length; i++) {
								if (originalLines[i] !== newLines[i]) {
									logger.info(`    ${chalk.red(`- ${originalLines[i]}`)}`);
									logger.info(`    ${chalk.green(`+ ${newLines[i]}`)}`);
								}
							}
						}

						// å§‹ç»ˆæ›´æ–°ç»Ÿè®¡æ•°æ®ï¼Œå³ä½¿æ˜¯ dry run æ¨¡å¼
						result.files.push(file);
						result.modifiedFiles++;
						packageModified = true;

						// åªåœ¨é dry run æ¨¡å¼ä¸‹å®é™…å†™å…¥æ–‡ä»¶
						if (!dryRun) {
							await fs.writeFile(file, content);
						}

						// if (!dryRun) {
						// 	await fs.writeFile(file, content);
						// 	result.files.push(file);
						// 	result.modifiedFiles++;
						// 	packageModified = true;
						// }
					}
				} catch (error) {
					const err = error instanceof Error ? error : new Error(String(error));
					logger.error(`Error processing file ${file}: ${err.message}`);
				}
			}
		} catch (error) {
			const err = error instanceof Error ? error : new Error(String(error));
			logger.error(
				`Error processing source files in ${pkg.location}: ${err.message}`,
			);
		}

		if (packageModified) {
			result.modifiedPackages++;
		}
	}

	// 3. æ›´æ–°æ ¹ç›®å½• package.json (å¦‚æœå­˜åœ¨)
	try {
		const rootPackageJsonPath = path.join(process.cwd(), "package.json");
		const rootPackageJson = await readJsonFile(rootPackageJsonPath);
		let rootModified = false;

		// æ£€æŸ¥ä¾èµ–é¡¹
		const dependencyTypes = [
			"dependencies",
			"devDependencies",
			"peerDependencies",
			"optionalDependencies",
		];

		for (const depType of dependencyTypes) {
			if (rootPackageJson[depType]) {
				const updatedDeps: Record<string, string> = {};
				let depsModified = false;

				for (const [dep, version] of Object.entries(rootPackageJson[depType])) {
					if (dep.startsWith(oldOrgNormalized)) {
						const newDep = dep.replace(oldOrgNormalized, newOrgNormalized);
						logger.info(`Root ${chalk.cyan(dep)} â†’ ${chalk.green(newDep)}`);
						updatedDeps[newDep] = version as string;
						depsModified = true;
						rootModified = true;
					} else {
						updatedDeps[dep] = version as string;
					}
				}

				if (depsModified && !dryRun) {
					rootPackageJson[depType] = updatedDeps;
				}
			}
		}

		// æ£€æŸ¥å…¶ä»–å¯èƒ½åŒ…å«ç»„ç»‡åçš„å­—æ®µ (å¦‚ workspaces é…ç½®)
		if (rootPackageJson.workspaces) {
			// å¤„ç† workspaces æ•°ç»„æˆ–å¯¹è±¡
			if (Array.isArray(rootPackageJson.workspaces)) {
				rootPackageJson.workspaces = rootPackageJson.workspaces.map(
					(workspace: string) => {
						if (workspace.includes(oldOrgNormalized)) {
							const newWorkspace = workspace.replace(
								new RegExp(escapeRegExp(oldOrgNormalized), "g"),
								newOrgNormalized,
							);
							logger.info(
								`Root workspace pattern ${chalk.cyan(workspace)} â†’ ${chalk.green(newWorkspace)}`,
							);
							rootModified = true;
							return newWorkspace;
						}
						return workspace;
					},
				);
			} else if (
				rootPackageJson.workspaces.packages &&
				Array.isArray(rootPackageJson.workspaces.packages)
			) {
				rootPackageJson.workspaces.packages =
					rootPackageJson.workspaces.packages.map((workspace: string) => {
						if (workspace.includes(oldOrgNormalized)) {
							const newWorkspace = workspace.replace(
								new RegExp(escapeRegExp(oldOrgNormalized), "g"),
								newOrgNormalized,
							);
							logger.info(
								`Root workspace pattern ${chalk.cyan(workspace)} â†’ ${chalk.green(newWorkspace)}`,
							);
							rootModified = true;
							return newWorkspace;
						}
						return workspace;
					});
			}
		}

		// ä¿å­˜æ ¹ package.json
		if (rootModified && !dryRun) {
			await writeJsonFile(rootPackageJsonPath, rootPackageJson);
			result.files.push(rootPackageJsonPath);
			result.modifiedFiles++;
		}

		// 4. æ£€æŸ¥æ ¹ç›®å½•ä¸‹çš„å…¶ä»–é…ç½®æ–‡ä»¶
		const rootConfigFiles = [
			"tsconfig.json",
			"jest.config.js",
			"jest.config.ts",
			"webpack.config.js",
			"rollup.config.js",
			"vite.config.js",
			"vite.config.ts",
		];

		for (const configFile of rootConfigFiles) {
			const configPath = path.join(process.cwd(), configFile);
			try {
				if ((await fs.stat(configPath)).isFile()) {
					const content = await fs.readFile(configPath, "utf-8");
					const originalContent = content;

					// ä½¿ç”¨ç›¸åŒçš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼è¿›è¡Œæ›¿æ¢
					const updatedContent = content.replace(
						new RegExp(escapeRegExp(oldOrgNormalized), "g"),
						newOrgNormalized,
					);

					if (updatedContent !== originalContent) {
						logger.info(
							`Found organization reference in ${chalk.cyan(configFile)}`,
						);

						if (!dryRun) {
							await fs.writeFile(configPath, updatedContent);
							result.files.push(configPath);
							result.modifiedFiles++;
						}
					}
				}
			} catch (error) {
				// å¿½ç•¥ä¸å­˜åœ¨çš„æ–‡ä»¶
				if ((error as NodeJS.ErrnoException).code !== "ENOENT") {
					const err = error instanceof Error ? error : new Error(String(error));
					logger.verbose(
						`Error checking config file ${configFile}: ${err.message}`,
					);
				}
			}
		}
	} catch (error) {
		const err = error instanceof Error ? error : new Error(String(error));
		logger.error(`Error processing root package.json: ${err.message}`);
	}

	// ç»“æœæ‘˜è¦
	if (dryRun) {
		logger.info(
			chalk.yellow(
				`Dry run completed. Would modify ${result.modifiedFiles} files in ${result.modifiedPackages} packages`,
			),
		);
	} else {
		logger.info(
			chalk.green(
				`Successfully renamed from ${oldOrgNormalized} to ${newOrgNormalized}`,
			),
		);
		logger.info(
			chalk.green(
				`Modified ${result.modifiedFiles} files in ${result.modifiedPackages} packages`,
			),
		);
	}

	return result;
}

/**
 * è½¬ä¹‰æ­£åˆ™è¡¨è¾¾å¼ç‰¹æ®Šå­—ç¬¦
 */
function escapeRegExp(string: string): string {
	return string.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
}

/**
 * è·å–æŒ‡å®šç›®å½•ä¸‹ç¬¦åˆæ¡ä»¶çš„æºæ–‡ä»¶
 */
async function getSourceFiles(
	dir: string,
	include: string[] = ["**/*.{js,jsx,ts,tsx,json,md,vue}"],
	exclude: string[] = [
		"**/node_modules/**",
		"**/dist/**",
		"**/build/**",
		"**/.git/**",
	],
): Promise<string[]> {
	const defaultInclude = ["**/*.{js,jsx,ts,tsx,json,md,vue}"];
	const defaultExclude = [
		"**/node_modules/**",
		"**/dist/**",
		"**/build/**",
		"**/.git/**",
	];

	const patterns = include && include.length > 0 ? include : defaultInclude;
	const ignorePatterns =
		exclude && exclude.length > 0 ? exclude : defaultExclude;

	const allFiles: string[] = [];

	for (const pattern of patterns) {
		const files = await glob(pattern, {
			cwd: dir,
			ignore: ignorePatterns,
			absolute: true,
			nodir: true,
		});
		allFiles.push(...files);
	}

	return Array.from(new Set(allFiles)); // å»é‡
}
